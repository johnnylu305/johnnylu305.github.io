<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Cheng-You Lu</title>

    <meta name="author" content="Cheng-You Lu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Cheng-You Lu
                </p>
		<p>I am a PhD student at the University of Technology Sydney's <a href="https://www.uts.edu.au/research/human-centric-artificial-intelligence-centre">Human-centric Artificial Intelligence Centre</a> in Australia. My research focuses on developing a <a href="https://www.linkedin.com/posts/cheng-you-lu_the-autonomous-3d-reconstruction-pipeline-activity-7225718046118621184-avQH?utm_source=share&utm_medium=member_desktop">3D reconstruction system using drones</a>, supervised by Prof. <a href="https://scholar.google.com.tw/citations?user=nubkF1cAAAAJ&hl=en">Chin-Teng Lin</a> from UTS and co-advised by Prof. <a href="https://yulunalexliu.github.io/">Yu-Lun Liu</a> from NYCU. I also have an informal cooperation with Prof. <a href="https://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a> from Brown University.
		</p>
                <p>
 		<p>
		I received my Master's degree in Computer Science from Brown University under the supervision of Prof. <a href="https://cs.brown.edu/people/ssrinath/">Srinath Sridhar</a>. I earned my Bachelor's degree in Computer Science from NYCU under the supervision of Prof. <a href="https://sites.google.com/g2.nctu.edu.tw/wpeng">Wen-Hsiao Peng</a>.
		</p>
		</p>                 
                </p>
                <p style="text-align:center">
                  <a href="mailto:cheng-you.lu@student.uts.edu.au">Email</a> &nbsp;/&nbsp;
                  <a href="data/Resume_20240920.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=uQ3K_xYAAAAJ&hl=zh-TW">Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/johnnylu305">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/cheng-you-lu/?originalSubdomain=au">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/ChengYou.jpeg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/ChengYou.jpeg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
              <h2>News</h2>
              <ul style="font-size: 16px;">
              <li>02/2025: One paper accepted by CHI 2025</li>
              <li>01/2025: Serve as a reviewer for CVPR 2025</li>
              <li>10/2024: Serve as a reviewer for ICLR 2025</li>
              <li>09/2024: Serve as a reviewer for AAAI 2025</li>
              <li>06/2024: Serve as a reviewer for <a href="https://neurips.cc/Conferences/2024/ProgramCommittee" style="font-size: 16px;">NeurIPS</a> 2024</li>
              <li>06/2024: Serve as a reviewer for Transactions on Artificial Intelligence</li>
              <li>04/2024: Serve as a reviewer for ICRA RoboNeRF 2024</li>
              <li>03/2024: Awarded the Taiwan Government Scholarship to study abroad 2024-2026</li>
              <li>02/2024: One paper accepted by CVPR 2024 Highlight</li>
              <li>01/2024: Serve as a reviewer for <a href="https://cvpr.thecvf.com/Conferences/2024/ProgramCommittee" style="font-size: 16px;">CVPR</a> 2024.</li>
	      </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="diva360_stop()" onmouseover="diva360_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='aegis_image'><video  width=100% muted autoplay loop>
          <source src="images/AEGIS_CHI.mp4" type="video/mp4">         
          Your browser does not support the video tag.
          </video></div>
          <img src='images/aegis_null.png' width=100%>
        </div>
        <script type="text/javascript">
          function aegis_start() {
            document.getElementById('aegis_null').style.opacity = "1";
          }

          function aegis_stop() {
            document.getElementById('aegis_null').style.opacity = "0";
          }
          diva360_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="data/AEGIS_20250327.pdf">
          <span class="papertitle">AEGIS: Human Attention-based Explainable Guidance for Intelligent Vehicle Systems</span>
        </a>
        <br>
				
	Zhuoli Zhuang, <strong>Cheng-You Lu</strong>, Yu-Cheng Fred Chang, Yu-Kai Wang, Thomas Do, Chin-Teng Lin

        <br>
        <em>CHI</em>, 2025 
        <br>
        <a href="data/AEGIS_20250327.pdf">project page</a>
        /
        <a href="data/AEGIS_20250327.pdf">arXiv</a>
        <p></p>
        <p>
        AEGIS, a Human Attention-based Explainable Guidance for Intelligent Vehicle Systems, leverages a pretrained human attention model to identify critical regions of interest for decision-making.
        </p>
      </td>
    </tr>

    <tr onmouseout="HFGaussian_stop()" onmouseover="HFGaussian_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='HFGaussian_image'><video  width=100% muted autoplay loop>
          <source src="images/HFGaussian.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/HFGaussian.png' width=100%>
        </div>
        <script type="text/javascript">
          function HFGaussian_start() {
            document.getElementById('HFGaussian_image').style.opacity = "1";
          }

          function HFGaussian_stop() {
            document.getElementById('HFGaussian_image').style.opacity = "0";
          }
          NeuralODF_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2411.03086">
          <span class="papertitle">HFGaussian: Learning Generalizable Gaussian Human with Integrated Human Features</span>
        </a>
        <br>
	Arnab Dey, <strong>Cheng-You Lu</strong>, Andrew I. Comport, Srinath Sridhar, Chin-Teng Lin, Jean Martinet
        <br>
        <em>Technical Report</em>, 2024
        <br>
        <a href="https://arxiv.org/abs/2411.03086">project page</a>
        /
        <a href="https://arxiv.org/abs/2411.03086">arXiv</a>
        <p></p>
        <p>
          HFGaussian, a generalizable 3D Gaussian Splatting that can estimate novel views and human features, including the 3D skeleton, 3D keypoints, and dense pose, from sparse input images in real time.
        </p>
      </td>
    </tr>

    <tr onmouseout="diva360_stop()" onmouseover="diva360_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='diva360_image'><video  width=100% muted autoplay loop>
          <source src="images/diva360_icon.mp4" type="video/mp4">         
          Your browser does not support the video tag.
          </video></div>
          <img src='images/diva360_null.png' width=100%>
        </div>
        <script type="text/javascript">
          function diva360_start() {
            document.getElementById('diva360_null').style.opacity = "1";
          }

          function diva360_stop() {
            document.getElementById('diva360_null').style.opacity = "0";
          }
          diva360_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ivl.cs.brown.edu/research/diva">
          <span class="papertitle">DiVa-360: The Dynamic Visual Dataset for Immersive Neural Fields</span>
        </a>
        <br>
				
	<strong>Cheng-You Lu<sup>1</sup></strong>, Peisen Zhou<sup>1</sup>, Angela Xing<sup>1</sup>, Chandradeep Pokhariya
        , Arnab Dey, Ishaan N Shah, Rugved Mavidipalli, Dylan Hu, Andrew Comport
        , Kefan Chen, Srinath Sridhar

        <br>
        <em>CVPR</em>, 2024 <font color="red"><strong>(Highlight)</strong></font>
        <br>
        <a href="https://ivl.cs.brown.edu/research/diva">project page</a>
        /
        <a href="https://arxiv.org/abs/2307.16897">arXiv</a>
        <p></p>
        <p>
        A high-quality and high-frame-rate multi-view dataset for long-duration dynamic radiance fields.
        </p>
      </td>
    </tr>


    <tr onmouseout="NeuralODF_stop()" onmouseover="NeuralODF_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='NeuralODF_image'><video  width=100% muted autoplay loop>
          <source src="images/NeuralODF.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/NeuralODF.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function NeuralODF_start() {
            document.getElementById('NeuralODF_image').style.opacity = "1";
          }

          function NeuralODF_stop() {
            document.getElementById('NeuralODF_image').style.opacity = "0";
          }
          NeuralODF_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://arxiv.org/abs/2206.05837">
          <span class="papertitle">NeuralODF: Learning Omnidirectional Distance Fields for 3D Shape Representation</span>
        </a>
        <br>
	Trevor Houchens<sup>1</sup>, <strong>Cheng-You Lu<sup>1</sup></strong>, Shivam Duggal, Rao Fu, Srinath Sridhar
        <br>
        <em>Technical Report</em>, 2022
        <br>
        <a href="https://arxiv.org/abs/2206.05837">project page</a>
        /
        <a href="https://arxiv.org/abs/2206.05837">arXiv</a>
        <p></p>
        <p>
          Omnidirectional Distance Fields (ODFs), a 3D shape representation that stores distances from any 3D position in any direction, along with efficient algorithms for converting ODFs to and from common 3D formats.
        </p>
      </td>
    </tr>


    <tr onmouseout="MIMOVRN_stop()" onmouseover="MIMOVRN_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='MIMOVRN_image'><video  width=100% muted autoplay loop>
          <source src="images/MIMOVRN.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/MIMOVRN.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function MIMOVRN_start() {
            document.getElementById('MIMOVRN_null').style.opacity = "1";
          }

          function MIMOVRN_stop() {
            document.getElementById('MIMOVRN_null').style.opacity = "0";
          }
          MIMOVRN_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://ding3820.github.io/MIMO-VRN/">
          <span class="papertitle">Video Rescaling Networks with Joint Optimization Strategies for Downscaling and Upscaling</span>
        </a>
        <br>
	Yan-Cheng Huang, Yi-Hsin Chen, <strong>Cheng-You Lu</strong>, Hui-Po Wang, Wen-Hsiao Peng, Ching-Chun Huang
        <br>
        <em>CVPR</em>, 2021
        <br>
        <a href="https://ding3820.github.io/MIMO-VRN/">project page</a>
        /
        <a href="https://arxiv.org/abs/2103.14858">arXiv</a>
        <p></p>
        <p>
        Multi-input Multi-output Video Rescaling Network (MIMO-VRN), a new strategy for downscaling and upscaling a group of video frames simultaneously.  
        </p>
      </td>
    </tr>


    <tr onmouseout="WSGCN_stop()" onmouseover="WSGCN_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='WSGCN_image'><video  width=100% muted autoplay loop>
          <source src="images/WSGCN.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/WSGCN.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function WSGCN_start() {
            document.getElementById('WSGCN_Image').style.opacity = "1";
          }

          function WSGCN_stop() {
            document.getElementById('WSGCN_Image').style.opacity = "0";
          }
          WSGCN_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://mapl.cs.nycu.edu.tw/WSGCN/">
          <span class="papertitle">Weakly-Supervised Image Semantic Segmentation Using Gaph Convolutional Networks</span>
        </a>
        <br>
	Shun-Yi Pan<sup>1</sup>, <strong>Cheng-You Lu<sup>1</sup></strong>, Shih-Po Lee, Wen-Hsiao Peng
        <br>
        <em>ICME</em>, 2021
        <br>
        <a href="https://mapl.cs.nycu.edu.tw/WSGCN/">project page</a>
        /
        <a href="https://arxiv.org/abs/2103.16762">arXiv</a>
        <p></p>
        <p>
        A GCN-based framework for weakly-supervised image semantic segmentation, improving pseudo label quality via Laplacian and entropy regularization.
        </p>
      </td>
    </tr>



          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
		Template from <a href="https://jonbarron.info/">Jon Barron</a>
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
